{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "from ppnp.tensorflow import PPNP\n",
    "from ppnp.tensorflow.training import train_model\n",
    "from ppnp.tensorflow.earlystopping import stopping_args\n",
    "from ppnp.tensorflow.propagation import PPRExact, PPRPowerIteration\n",
    "from ppnp.data.io import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "First we need to load the dataset we want to train on. The datasets used are in the `SparseGraph` format. This is just a class providing the adjacency, attribute and label matrices in a dense (`np.ndarray`) or sparse (`scipy.sparse.csr_matrix`) matrix format and some (in principle unnecessary) convenience functions. If you want to use external datasets, you can e.g. use the `networkx_to_sparsegraph` method in `ppnp.data.io` for converting NetworkX graphs to our SparseGraph format.\n",
    "\n",
    "The four datasets from the paper (Cora-ML, Citeseer, PubMed and MS Academic) can be found in the directory `data`.\n",
    "\n",
    "For this example we choose the Cora-ML graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Undirected, unweighted and connected SparseGraph with 15962 edges (no self-loops). Data: adj_matrix (2810x2810), attr_matrix (2810x2879), labels (2810), node_names (2810), attr_names (2879), class_names (7)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_name = 'cora_ml'\n",
    "graph = load_dataset(graph_name)\n",
    "graph.standardize(select_lcc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up propagation\n",
    "\n",
    "Next we need to set up the proper propagation scheme. In the paper we've introduced the exact PPR propagation used in PPNP and the PPR power iteration propagation used in APPNP.\n",
    "\n",
    "Here we use the hyperparameters from the paper. Note that we should use a different `alpha = 0.2` for MS Academic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_ppnp = PPRExact(graph.adj_matrix, alpha=0.1)\n",
    "prop_appnp = PPRPowerIteration(graph.adj_matrix, alpha=0.1, niter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model hyperparameters\n",
    "\n",
    "Now we choose the hyperparameters. These are the ones used in the paper for all datasets.\n",
    "\n",
    "Note that we choose the propagation for APPNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'hiddenunits': [64],\n",
    "    'reg_lambda': 5e-3,\n",
    "    'learning_rate': 0.01,\n",
    "    'keep_prob': 0.5,\n",
    "    'propagation': prop_appnp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_split_args = {'ntrain_per_class': 20, 'nstopping': 500, 'nknown': 1500, 'seed': 2413340114}\n",
    "test = False\n",
    "save_result = False\n",
    "print_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-08 10:25:20: PPNP: {'hiddenunits': [64], 'reg_lambda': 0.005, 'learning_rate': 0.01, 'keep_prob': 0.5, 'propagation': <ppnp.tensorflow.propagation.PPRPowerIteration object at 0x7f44b14b4e80>}\n",
      "2019-03-08 10:25:20: Tensorflow seed: 2441633861\n",
      "2019-03-08 10:25:22: Step 0: Train loss = 2.26, train acc = 29.3, early stopping loss = 2.10, early stopping acc = 25.6 (1.209 sec)\n",
      "2019-03-08 10:25:23: Step 20: Train loss = 1.95, train acc = 66.4, early stopping loss = 1.95, early stopping acc = 56.4 (0.712 sec)\n",
      "2019-03-08 10:25:24: Step 40: Train loss = 1.90, train acc = 82.9, early stopping loss = 1.93, early stopping acc = 64.8 (0.627 sec)\n",
      "2019-03-08 10:25:24: Step 60: Train loss = 1.82, train acc = 83.6, early stopping loss = 1.91, early stopping acc = 63.4 (0.627 sec)\n",
      "2019-03-08 10:25:25: Step 80: Train loss = 1.77, train acc = 91.4, early stopping loss = 1.86, early stopping acc = 72.0 (0.638 sec)\n",
      "2019-03-08 10:25:26: Step 100: Train loss = 1.66, train acc = 91.4, early stopping loss = 1.81, early stopping acc = 74.4 (0.630 sec)\n",
      "2019-03-08 10:25:26: Step 120: Train loss = 1.62, train acc = 95.7, early stopping loss = 1.76, early stopping acc = 74.8 (0.648 sec)\n",
      "2019-03-08 10:25:27: Step 140: Train loss = 1.50, train acc = 96.4, early stopping loss = 1.70, early stopping acc = 78.6 (0.636 sec)\n",
      "2019-03-08 10:25:28: Step 160: Train loss = 1.49, train acc = 96.4, early stopping loss = 1.64, early stopping acc = 79.2 (0.641 sec)\n",
      "2019-03-08 10:25:28: Step 180: Train loss = 1.43, train acc = 98.6, early stopping loss = 1.59, early stopping acc = 80.4 (0.632 sec)\n",
      "2019-03-08 10:25:29: Step 200: Train loss = 1.33, train acc = 98.6, early stopping loss = 1.55, early stopping acc = 79.2 (0.634 sec)\n",
      "2019-03-08 10:25:30: Step 220: Train loss = 1.31, train acc = 99.3, early stopping loss = 1.51, early stopping acc = 81.4 (0.626 sec)\n",
      "2019-03-08 10:25:30: Step 240: Train loss = 1.33, train acc = 97.9, early stopping loss = 1.48, early stopping acc = 78.2 (0.616 sec)\n",
      "2019-03-08 10:25:31: Step 260: Train loss = 1.32, train acc = 100.0, early stopping loss = 1.44, early stopping acc = 82.2 (0.625 sec)\n",
      "2019-03-08 10:25:31: Step 280: Train loss = 1.23, train acc = 98.6, early stopping loss = 1.41, early stopping acc = 81.4 (0.628 sec)\n",
      "2019-03-08 10:25:32: Step 300: Train loss = 1.22, train acc = 99.3, early stopping loss = 1.38, early stopping acc = 82.6 (0.614 sec)\n",
      "2019-03-08 10:25:33: Step 320: Train loss = 1.12, train acc = 100.0, early stopping loss = 1.35, early stopping acc = 81.6 (0.634 sec)\n",
      "2019-03-08 10:25:33: Step 340: Train loss = 1.07, train acc = 100.0, early stopping loss = 1.34, early stopping acc = 83.0 (0.629 sec)\n",
      "2019-03-08 10:25:34: Step 360: Train loss = 1.11, train acc = 99.3, early stopping loss = 1.32, early stopping acc = 81.0 (0.629 sec)\n",
      "2019-03-08 10:25:35: Step 380: Train loss = 1.08, train acc = 98.6, early stopping loss = 1.29, early stopping acc = 83.4 (0.626 sec)\n",
      "2019-03-08 10:25:35: Step 400: Train loss = 1.10, train acc = 99.3, early stopping loss = 1.28, early stopping acc = 80.2 (0.636 sec)\n",
      "2019-03-08 10:25:36: Step 420: Train loss = 1.07, train acc = 100.0, early stopping loss = 1.26, early stopping acc = 80.8 (0.634 sec)\n",
      "2019-03-08 10:25:36: Step 440: Train loss = 1.02, train acc = 100.0, early stopping loss = 1.23, early stopping acc = 82.0 (0.633 sec)\n",
      "2019-03-08 10:25:37: Step 460: Train loss = 1.01, train acc = 100.0, early stopping loss = 1.26, early stopping acc = 81.0 (0.628 sec)\n",
      "2019-03-08 10:25:38: Step 480: Train loss = 1.02, train acc = 100.0, early stopping loss = 1.22, early stopping acc = 79.4 (0.638 sec)\n",
      "2019-03-08 10:25:38: Step 500: Train loss = 0.93, train acc = 100.0, early stopping loss = 1.20, early stopping acc = 82.8 (0.625 sec)\n",
      "2019-03-08 10:25:39: Step 520: Train loss = 0.87, train acc = 100.0, early stopping loss = 1.17, early stopping acc = 82.2 (0.625 sec)\n",
      "2019-03-08 10:25:40: Step 540: Train loss = 1.01, train acc = 99.3, early stopping loss = 1.16, early stopping acc = 82.2 (0.619 sec)\n",
      "2019-03-08 10:25:40: Step 560: Train loss = 1.01, train acc = 100.0, early stopping loss = 1.17, early stopping acc = 80.6 (0.617 sec)\n",
      "2019-03-08 10:25:41: Step 580: Train loss = 0.91, train acc = 100.0, early stopping loss = 1.13, early stopping acc = 82.8 (0.622 sec)\n",
      "2019-03-08 10:25:41: Step 600: Train loss = 0.90, train acc = 99.3, early stopping loss = 1.14, early stopping acc = 80.4 (0.623 sec)\n",
      "2019-03-08 10:25:42: Step 620: Train loss = 0.93, train acc = 100.0, early stopping loss = 1.13, early stopping acc = 80.6 (0.631 sec)\n",
      "2019-03-08 10:25:43: Step 640: Train loss = 0.90, train acc = 99.3, early stopping loss = 1.15, early stopping acc = 79.4 (0.627 sec)\n",
      "2019-03-08 10:25:43: Step 660: Train loss = 0.82, train acc = 100.0, early stopping loss = 1.11, early stopping acc = 80.6 (0.616 sec)\n",
      "2019-03-08 10:25:44: Step 680: Train loss = 0.88, train acc = 100.0, early stopping loss = 1.11, early stopping acc = 80.8 (0.637 sec)\n",
      "2019-03-08 10:25:45: Step 700: Train loss = 0.91, train acc = 100.0, early stopping loss = 1.10, early stopping acc = 80.2 (0.611 sec)\n",
      "2019-03-08 10:25:45: Step 720: Train loss = 0.83, train acc = 100.0, early stopping loss = 1.11, early stopping acc = 80.0 (0.621 sec)\n",
      "2019-03-08 10:25:46: Step 740: Train loss = 0.81, train acc = 100.0, early stopping loss = 1.10, early stopping acc = 81.6 (0.634 sec)\n",
      "2019-03-08 10:25:46: Step 760: Train loss = 0.89, train acc = 100.0, early stopping loss = 1.06, early stopping acc = 82.8 (0.618 sec)\n",
      "2019-03-08 10:25:47: Step 780: Train loss = 0.80, train acc = 100.0, early stopping loss = 1.05, early stopping acc = 83.0 (0.619 sec)\n",
      "2019-03-08 10:25:48: Step 800: Train loss = 0.85, train acc = 100.0, early stopping loss = 1.08, early stopping acc = 80.2 (0.620 sec)\n",
      "2019-03-08 10:25:48: Step 820: Train loss = 0.79, train acc = 100.0, early stopping loss = 1.06, early stopping acc = 80.2 (0.623 sec)\n",
      "2019-03-08 10:25:49: Step 840: Train loss = 0.82, train acc = 100.0, early stopping loss = 1.05, early stopping acc = 81.6 (0.620 sec)\n",
      "2019-03-08 10:25:50: Step 860: Train loss = 0.79, train acc = 99.3, early stopping loss = 1.01, early stopping acc = 82.4 (0.622 sec)\n",
      "2019-03-08 10:25:50: Step 880: Train loss = 0.83, train acc = 100.0, early stopping loss = 1.06, early stopping acc = 79.6 (0.619 sec)\n",
      "2019-03-08 10:25:51: Step 900: Train loss = 0.75, train acc = 100.0, early stopping loss = 1.02, early stopping acc = 81.6 (0.622 sec)\n",
      "2019-03-08 10:25:51: Step 920: Train loss = 0.85, train acc = 100.0, early stopping loss = 1.00, early stopping acc = 82.4 (0.620 sec)\n",
      "2019-03-08 10:25:52: Step 940: Train loss = 0.77, train acc = 99.3, early stopping loss = 1.02, early stopping acc = 80.6 (0.636 sec)\n",
      "2019-03-08 10:25:53: Step 960: Train loss = 0.75, train acc = 100.0, early stopping loss = 0.98, early stopping acc = 82.4 (0.632 sec)\n",
      "2019-03-08 10:25:53: Step 980: Train loss = 0.74, train acc = 100.0, early stopping loss = 1.00, early stopping acc = 82.2 (0.638 sec)\n",
      "2019-03-08 10:25:54: Step 1000: Train loss = 0.73, train acc = 100.0, early stopping loss = 0.99, early stopping acc = 83.2 (0.625 sec)\n",
      "2019-03-08 10:25:55: Step 1020: Train loss = 0.73, train acc = 100.0, early stopping loss = 0.99, early stopping acc = 83.4 (0.613 sec)\n",
      "2019-03-08 10:25:55: Step 1040: Train loss = 0.75, train acc = 100.0, early stopping loss = 0.99, early stopping acc = 83.0 (0.613 sec)\n",
      "2019-03-08 10:25:56: Step 1060: Train loss = 0.69, train acc = 100.0, early stopping loss = 0.96, early stopping acc = 83.8 (0.620 sec)\n",
      "2019-03-08 10:25:56: Step 1080: Train loss = 0.71, train acc = 100.0, early stopping loss = 0.96, early stopping acc = 82.4 (0.617 sec)\n",
      "2019-03-08 10:25:57: Step 1100: Train loss = 0.68, train acc = 100.0, early stopping loss = 1.00, early stopping acc = 79.8 (0.624 sec)\n",
      "2019-03-08 10:25:58: Step 1120: Train loss = 0.72, train acc = 100.0, early stopping loss = 1.00, early stopping acc = 81.6 (0.630 sec)\n",
      "2019-03-08 10:25:58: Step 1140: Train loss = 0.68, train acc = 100.0, early stopping loss = 0.94, early stopping acc = 82.2 (0.614 sec)\n",
      "2019-03-08 10:25:59: Step 1160: Train loss = 0.68, train acc = 100.0, early stopping loss = 0.95, early stopping acc = 81.6 (0.628 sec)\n",
      "2019-03-08 10:25:59: Step 1180: Train loss = 0.72, train acc = 100.0, early stopping loss = 0.99, early stopping acc = 81.6 (0.623 sec)\n",
      "2019-03-08 10:26:00: Step 1200: Train loss = 0.63, train acc = 100.0, early stopping loss = 0.95, early stopping acc = 80.8 (0.630 sec)\n",
      "2019-03-08 10:26:01: Step 1220: Train loss = 0.65, train acc = 99.3, early stopping loss = 0.94, early stopping acc = 82.6 (0.636 sec)\n",
      "2019-03-08 10:26:01: Step 1240: Train loss = 0.62, train acc = 100.0, early stopping loss = 0.93, early stopping acc = 83.0 (0.629 sec)\n",
      "2019-03-08 10:26:02: Step 1260: Train loss = 0.70, train acc = 100.0, early stopping loss = 0.94, early stopping acc = 83.6 (0.623 sec)\n",
      "2019-03-08 10:26:03: Step 1280: Train loss = 0.64, train acc = 100.0, early stopping loss = 0.96, early stopping acc = 81.4 (0.620 sec)\n",
      "2019-03-08 10:26:03: Step 1300: Train loss = 0.64, train acc = 100.0, early stopping loss = 0.93, early stopping acc = 81.6 (0.627 sec)\n",
      "2019-03-08 10:26:04: Step 1320: Train loss = 0.64, train acc = 100.0, early stopping loss = 0.90, early stopping acc = 83.6 (0.627 sec)\n",
      "2019-03-08 10:26:05: Step 1340: Train loss = 0.65, train acc = 100.0, early stopping loss = 0.92, early stopping acc = 83.2 (0.618 sec)\n",
      "2019-03-08 10:26:05: Step 1360: Train loss = 0.71, train acc = 100.0, early stopping loss = 0.94, early stopping acc = 82.4 (0.624 sec)\n",
      "2019-03-08 10:26:06: Step 1380: Train loss = 0.68, train acc = 100.0, early stopping loss = 0.96, early stopping acc = 79.2 (0.618 sec)\n",
      "2019-03-08 10:26:06: Step 1400: Train loss = 0.65, train acc = 100.0, early stopping loss = 0.96, early stopping acc = 80.2 (0.620 sec)\n",
      "2019-03-08 10:26:06: Last step: 1402, best step: 770 (45.173 sec)\n",
      "2019-03-08 10:26:07: Early stopping accuracy: 84.8%, early stopping F1 score: 0.835\n",
      "2019-03-08 10:26:07: Validation accuracy: 84.0%, test F1 score: 0.830\n"
     ]
    }
   ],
   "source": [
    "result = train_model(\n",
    "        graph_name, PPNP, graph, model_args, idx_split_args,\n",
    "        stopping_args, test, save_result, None, print_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
